{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = \"0.1.0\"\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "os.chdir(Path('/home/datawork-osmose/git_osmose_datarmor_2/source'))\n",
    "import subprocess\n",
    "from OSmOSE import Spectrogram, Job_builder, utils\n",
    "from time import sleep\n",
    "from IPython.display import Image\n",
    "\n",
    "path_osmose_dataset = \"/home/datawork-osmose/dataset/\"\n",
    "path_osmose_home = \"/home/datawork-osmose/\"\n",
    "env_name = \"osmose\"\n",
    "\n",
    "jb = Job_builder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:blue\">*JUST RUN CELL*</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.display_folder_storage_infos(path_osmose_home)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">*FILL & RUN CELLS*</span> Dataset preparation\n",
    "\n",
    "- ``dataset_name`` is the name of the dataset to be processed;\n",
    "- ``dataset_sr`` is the sample frequency you want to use for your analysis, which can be different from the original one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'MPSU_ForestouHuella'\n",
    "\n",
    "save_matrix = False # Set to True if you want to generate the numpy matrices\n",
    "\n",
    "local_execution = False # Change to True if you execute this notebook on your computer and not on datarmor\n",
    "date_template = \"\" # strftime format, used to build the dataset from scratch (ignore if the dataset is already built)\n",
    "dataset = Spectrogram(dataset_path =Path(path_osmose_dataset, dataset_name), owner_group=\"gosmose\", local=local_execution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset subset\n",
    "\n",
    "Note that you can process only a subset of your entire dataset by creating the file `/home/datawork-osmose/dataset/dataset_ID/analysis/subset_files.csv`, which is a simple list of files to be processed, for example:\n",
    "\n",
    "`% head /home/datawork-osmose/dataset/fecampOWFSOMM/analysis/subset_files.csv\n",
    "channelA_2020_11_20_15_40_17.wav\n",
    "channelA_2020_11_20_15_43_20.wav\n",
    "channelA_2020_11_20_16_20_17.wav\n",
    "channelA_2020_11_20_16_23_20.wav\n",
    "channelA_2020_11_20_16_30_17.wav\n",
    "channelA_2020_11_20_16_33_20.wav\n",
    "channelA_2020_11_20_16_43_20.wav\n",
    "channelA_2020_11_20_16_50_17.wav\n",
    "channelA_2020_11_20_16_53_20.wav\n",
    "channelA_2020_11_20_17_10_17.wav\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">*FILL & RUN CELLS*</span> Configure spectrogram parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main parameters \n",
    "\n",
    "Start by setting the value of `spectro_duration` in seconds. It corresponds to the maximal duration of the spectrogram display window. If it is different than the original file duration, you have to reshape the audio files to fit this time window.\n",
    "\n",
    "Then, you can set the value of `zoom_levels`, which is the number of zoom levels you want (they are used in our web-based annotation tool APLOSE). With `zoom_levels = 0`, your shortest spectrogram display window has a duration of `spectro_duration` seconds (that is no zoom at all) ; with `zoom_levels = 1`, a duration of `spectro_duration`/2 seconds ; with `zoom_levels = 2`, a duration of `spectro_duration`/4 seconds ...\n",
    "\n",
    "After that, you can set the following classical spectrogram parameters : `nfft` (in samples), `winsize` (in samples), `overlap` (in \\%). **Note that with those parameters you set the resolution of your spectrogram display window with the smallest duration, obtained with the highest zoom level.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.zoom_level = 1\n",
    "\n",
    "dataset.nfft = 2048 # samples\n",
    "dataset.window_size = 1024 # samples\n",
    "dataset.overlap = 95 # %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two following characteristics are set as identical to the original audio files by default. Change them and run the cell below only if you want other parameters for the audio files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.spectro_duration = 20\n",
    "dataset.dataset_sr = 16000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amplitude normalization \n",
    "\n",
    "Eventually, we also propose you different modes of data/spectrogram normalization.\n",
    "\n",
    "Normalization over raw data samples with the variable `data_normalization` (default value `''`, i.e. no normalization) :\n",
    "- instrument-based normalization with the three parameters `sensitivity_dB` (in dB, default value = 0), `gain` (in dB, default value = 0) and `peak_voltage` (in V, default value = 1). Using default values, no normalization will be performed ;\n",
    "\n",
    "- z-score normalization over a given time period through the variable `zscore_duration`, applied directly on your raw timeseries. The possible values are:\n",
    "    - `zscore_duration = 'original'` : the audio file duration will be used as time period ;\n",
    "    - `zscore_duration = '10H'` : any time period put as a string using classical [time alias](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#timeseries-offset-aliases). This period should be higher than your file duration. \n",
    "\n",
    "Normalization over spectra with the variable `spectro_normalization` (default value `'density'`, see OSmOSEanalytics/documentation/theory_spectrogram.pdf for details) :\n",
    "- density-based normalization by setting `spectro_normalization = 'density'`\n",
    "- spectrum-based normalization by setting `spectro_normalization = 'spectrum'` \n",
    "\n",
    "In the cell below, you can also have access to the amplitude dynamics in dB throuh the parameters `dynamic_max` and `dynamic_min`, the colormap `spectro_colormap` to be used (see possible options in the [documentation](https://matplotlib.org/stable/tutorials/colors/colormaps.html)) and specify the frequency cut `HPfilter_freq_min` of a high-pass filter if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.data_normalization = 'instrument' # 'instrument' OR 'zscore'\n",
    "\n",
    "dataset.zscore_duration = 'original' # parameter for 'zscore' mode, values = time alias OR 'original' \n",
    "dataset.sensitivity = -164 # parameter for 'instrument' mode\n",
    "dataset.gain_dB = 14.7 # parameter for 'instrument' mode\n",
    "dataset.peak_voltage = 2.5 # parameter for 'instrument' mode\n",
    "\n",
    "dataset.spectro_normalization = 'density' # 'density' OR 'spectrum' \n",
    "\n",
    "dataset.dynamic_max = 120\n",
    "dataset.dynamic_min = 0\n",
    "dataset.colormap = 'viridis'\n",
    "\n",
    "dataset.hp_filter_min_freq = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter adjustement \n",
    "\n",
    "\n",
    "In the cell below you can **check your spectrogram dimension w.r.t your screen resolution** (just run it). We calculate the number of time windows (or equivalently, the number of spectra) you have in your shortest spectrogram display window.\n",
    "\n",
    "Be aware that this number should be as close as your horizontal screen resolution (ie approximately 2000 pixels, as a classical screen resolution is 1920x1080 pixels (horizontal pixels) x (vertical pixels) ) to avoid numerical compression during image display on your screen, as well as useless over-resoluted spectrograms obtained at a high computational cost. We warn you if you are higher, but you can still compute higher-resolution spectrograms if you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.check_spectro_size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">*FILL & RUN CELL*</span> Adjust spectrogram parameters and initialize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`dataset.number_adjustment_spectrograms` is the number of spectrogram examples used to adjust your parameters. If you are really not sure about your parameters, it is better to start with a small number, because each time you will have to wait for the generation of all your `dataset.number_adjustment_spectrograms` (x the different zoom levels) spectrograms before being able to re-generate spectrograms with another set of parameters.\n",
    "\n",
    "`dataset.batch_number` indicates the number of concurrent jobs. A higher number can speed things up until a certain point. It still does not work very well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.number_adjustment_spectrogram = 5\n",
    "dataset.batch_number = 6\n",
    "\n",
    "reshape_method = \"classic\" # Automatically reshape the audio files to fit the spectro_duration value. Available methods : \"classic\" or \"legacy\"\n",
    "merge_on_reshape = False # Set to False if fyou don't want to merge audio files while reshaping them (if they do not follow each other chronologically for example)\n",
    "force_init = False # Force every initialization parameter, including force_reshape and other computing jobs. It is best to avoid using it.\n",
    "dataset.initialize(reshape_method=reshape_method, date_template=date_template, force_init=force_init, merge_on_reshape=merge_on_reshape)\n",
    "dataset.update_parameters(dataset.path.joinpath(\"processed\",\"spectrogram\",\"adjust_metadata.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">*JUST RUN CELL*</span> Adjust spectrogram parameters\n",
    "\n",
    "### Compute `dataset.number_adjustment_spectrograms` spectrograms to adjust parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_list = [] # Fill audio file names when you want to generate specific adjustment spectrograms\n",
    "jobfile = jb.build_job_file(script_path=Path(os.getcwd(), \"qsub_spectrogram_generator_pkg.py\"), \\\n",
    "            script_args=f\"\"\"--nb-adjust-files {dataset.number_adjustment_spectrogram} \\\n",
    "            --dataset-path {dataset.path} \\\n",
    "            --dataset-sr {dataset.dataset_sr} \\\n",
    "            --files \"{\" \".join(file_list)}\" \"\"\",\n",
    "            jobname=\"OSmOSE_AdjustSpectro\", \n",
    "            preset=\"low\",\n",
    "            env_name=env_name,\n",
    "            mem=\"20G\",\n",
    "            walltime=\"01:00:00\",\n",
    "            logdir=dataset.path.joinpath(\"log\"))\n",
    "\n",
    "pending_jobs = [jobid for jobid in dataset.pending_jobs if b\"finished\" not in subprocess.run([\"qstat\",jobid], capture_output=True).stderr]\n",
    "job_id = jb.submit_job(dependency=pending_jobs) #submit all built job files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize `nberAdjustSpectros` spectrograms to adjust parameters. \n",
    "\n",
    "Re-run several times this cell to update the folder of images because they keep being generated while you visualize them. If this set of parameters does not suit you, change them and re-run new spectrograms with the previous cells, as many times as you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if jb.ongoing_jobs:\n",
    "    print(f\"\\rParameter adjustment is still running, come back later!\")\n",
    "else:\n",
    "    print(\"\\rParameter adjustment finished!                           \")\n",
    "\n",
    "    path_output_spectro = dataset.path_output_spectrogram.parent.parent.joinpath(\"adjustment_spectros\",\"image\")\n",
    "    if not (path_output_spectro.exists() and len(os.listdir(path_output_spectro))>0):\n",
    "        jb.read_output_file(outtype = \"out\", job_file_name=jb.finished_jobs[-1][\"outfile\"])\n",
    "        raise UserWarning(\"Something went wrong with the spectro adjustment job. Full job trace above.\")\n",
    "\n",
    "    spectro_list = os.listdir(path_output_spectro)\n",
    "    for spectro in spectro_list:\n",
    "        display(Image(path_output_spectro.joinpath(spectro)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DONE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">*JUST RUN CELL*</span>  Prepare spectrogram generation\n",
    "\n",
    "Just one thing : if you create your spectrograms for an APLOSE campaign, set `write_datasets_csv_for_APLOSE=True` below !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_datasets_csv_for_APLOSE=False \n",
    "\n",
    "if write_datasets_csv_for_APLOSE:\n",
    "\n",
    "    dataset_csv = Path(path_osmose_dataset, \"datasets.csv\")\n",
    "    \n",
    "    dataset_name = f\"{dataset.name} ({dataset.spectro_duration}_{dataset.dataset_sr})\"\n",
    "    dataset_info = {'name': dataset_name,\n",
    "           'folder_name': dataset.name,\n",
    "           'conf_folder': f\"{dataset.spectro_duration}_{dataset.dataset_sr}\",\n",
    "           'dataset_type_name':'',\n",
    "           'dataset_type_desc':'',\n",
    "           'files_type': '.wav',\n",
    "           'location_name': '',\n",
    "           'location_desc': '',\n",
    "           'location_lat':'',\n",
    "           'location_lon':''}\n",
    "\n",
    "    if dataset_csv.exists():\n",
    "        meta = pd.read_csv(dataset_csv)\n",
    "        if dataset_name not in meta['name'].values:\n",
    "            meta = meta.append(dataset_info, ignore_index = True)\n",
    "            meta.sort_values(by=['folder_name'], ascending=False)\n",
    "            meta.to_csv(dataset_csv , index=False)\n",
    "\n",
    "    else:\n",
    "        met=pd.DataFrame.from_records([df2]) \n",
    "        met.to_csv(dataset_csv , index=False)        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">*JUST RUN CELL*</span> Launch spectrogram generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**if this cell fails, run it again please, can faile twice in a row**\n",
    "\n",
    "You might want to increase the dataset.batch_number if the files needs to be split up in more than 10 groups, or decrease it if 10 groups are too much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.batch_number = 10\n",
    "all_files = list(dataset.audio_path.glob(\"*.wav\"))\n",
    "batch_size = len(all_files) // dataset.batch_number\n",
    "\n",
    "if dataset.jb.ongoing_jobs:\n",
    "    print(f\"\\rPlease wait for the following jobs to finish: {','.join([jobinfo['path'] for jobinfo in dataset.jb.ongoing_jobs])}\", end=\"\")\n",
    "else:\n",
    "\n",
    "    print(\"\\rAll previous jobs are completed, ready to launch spectrograms\")\n",
    "\n",
    "    for batch in range(dataset.batch_number):\n",
    "        i_min = batch * batch_size\n",
    "        i_max = (i_min + batch_size if batch < dataset.batch_number - 1 else len(all_files)) # If it is the last batch, take all files\n",
    "\n",
    "        jobfile = jb.build_job_file(script_path=Path(os.getcwd(),\"qsub_spectrogram_generator_pkg.py\"), \\\n",
    "                    script_args=f\"--dataset-path {dataset.path}\\\n",
    "                    --dataset-sr {dataset.dataset_sr} \\\n",
    "                    --batch-ind-min {i_min}\\\n",
    "                    --batch-ind-max {i_max}\\\n",
    "                    {'--save-matrix' if save_matrix else ''}\", \n",
    "                    jobname=\"OSmOSE_SpectroGenerator\", \n",
    "                    preset=\"low\",\n",
    "                    env_name=env_name,\n",
    "                    mem=\"70G\",\n",
    "                    walltime=\"10:00:00\",\n",
    "                    logdir=dataset.path.joinpath(\"log\"))\n",
    "\n",
    "\n",
    "    job_id_list = jb.submit_job() #submit all built job files\n",
    "    nb_jobs = len(jb.finished_jobs) + len(job_id_list)\n",
    "    \n",
    "    print(f\"The job ids are {job_id_list}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Track progress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check job status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if jb.ongoing_jobs:\n",
    "    spectros = len(os.listdir(dataset.path_output_spectrogram))\n",
    "    audio = len(os.listdir(dataset.audio_path))-2\n",
    "    total = audio * (2**dataset.zoom_level)-1\n",
    "    \n",
    "    print(f\"Ongoing jobs: {len(jb.ongoing_jobs)}/{nb_jobs}; Finished jobs: {len(jb.finished_jobs)}/{nb_jobs}...\")\n",
    "    print(f\"Spectrograms: {spectros}/{total} ({spectros*100//total}%).\")\n",
    " \n",
    "    \n",
    "else:\n",
    "    print(\"All jobs are finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read output files\n",
    "\n",
    "Use the cell below to read the output files of your job. You have two available job builders to chose from :\n",
    " \n",
    " - dataset.jb to read the output of dataset initialization jobs.\n",
    " - jb to read the output of spectrogram generation jobs.\n",
    " \n",
    "Once you've chosen the job_builder, select an output file name to read. You can set the read mode to err if you wish to read the error output file (usually empty)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_builder = jb #jb or dataset.jb\n",
    "\n",
    "job_builder.list_jobs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "job_to_read =\"OSmOSE_SpectroGenerator2\"\n",
    "read_mode = \"out\" # set to \"err\" to read the error output file\n",
    "\n",
    "job_builder.read_output_file(outtype = read_mode, job_name=job_to_read) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.jb.update_job_access()\n",
    "jb.update_job_access()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_id = \"\" # Get the job id from the list above\n",
    "\n",
    "!qstat -fx {job_id}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for jobinfo in job_builder.ongoing_jobs:\n",
    "    jobinfo[\"path\"].unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_builder.finished_jobs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:osmose_dev_dcazau]",
   "language": "python",
   "name": "conda-env-osmose_dev_dcazau-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "038fb172a99c9b7ee7474e984b9ff4962ea47b0ef555bcc216ed798a8387f59b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

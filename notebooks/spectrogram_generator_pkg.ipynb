{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(os.path.join('/home/datawork-osmose',[s for s in os.getcwd().split('/') if 'OSmOSEanalytics' in s][0],'source'))\n",
    "from OSmOSE import Spectrogram, job_factory\n",
    "from time import sleep\n",
    "\n",
    "path_osmose_dataset = \"/home/datawork-osmose/dataset/\"\n",
    "path_osmose_home = \"/home/datawork-osmose/\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">*FILL & RUN CELLS*</span> Dataset preparation\n",
    "\n",
    "- ``dataset_ID`` is the name of the dataset to be processed;\n",
    "- ``analysis_fs`` is the sample frequency you want to use for your analysis, which can be different from the original one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ID = ''\n",
    "analysis_fs = 240\n",
    "dataset = Spectrogram(os.path.join(path_osmose_dataset, dataset_ID), analysis_fs=analysis_fs)\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset subset\n",
    "\n",
    "Note that you can process only a subset of your entire dataset by creating the file `/home/datawork-osmose/dataset/dataset_ID/analysis/subset_files.csv`, which is a simple list of files to be processed, for example:\n",
    "\n",
    "`% head /home/datawork-osmose/dataset/fecampOWFSOMM/analysis/subset_files.csv\n",
    "channelA_2020_11_20_15_40_17.wav\n",
    "channelA_2020_11_20_15_43_20.wav\n",
    "channelA_2020_11_20_16_20_17.wav\n",
    "channelA_2020_11_20_16_23_20.wav\n",
    "channelA_2020_11_20_16_30_17.wav\n",
    "channelA_2020_11_20_16_33_20.wav\n",
    "channelA_2020_11_20_16_43_20.wav\n",
    "channelA_2020_11_20_16_50_17.wav\n",
    "channelA_2020_11_20_16_53_20.wav\n",
    "channelA_2020_11_20_17_10_17.wav\n",
    "`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">*FILL & RUN CELLS*</span> Configure spectrogram parameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main parameters \n",
    "\n",
    "Start by setting the value of `maxtime_display_spectro` in seconds. It corresponds to the maximal duration of the spectrogram display window. If it is different than the original file duration, you have to reshape the audio files to fit this time window.\n",
    "\n",
    "Then, you can set the value of `nber_tile_level`, which is the number of zoom levels you want (they are used in our web-based annotation tool APLOSE). With `nber_tile_level = 1`, your shortest spectrogram display window has a duration of `maxtime_display_spectro` seconds (that is no zoom at all) ; with `nber_tile_level = 2`, a duration of `maxtime_display_spectro`/2 seconds ; with `nber_tile_level = 3`, a duration of `maxtime_display_spectro`/4 seconds ...\n",
    "\n",
    "After that, you can set the following classical spectrogram parameters : `nfft` (in samples), `winsize` (in samples), `overlap` (in \\%). **Note that with those parameters you set the resolution of your spectrogram display window with the smallest duration, obtained with the highest zoom level.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxtime_display_spectro = 900 # this default value corresponds to your audio file duration\n",
    "\n",
    "nber_tile_level = 2\n",
    "\n",
    "nfft = 512 # samples\n",
    "winsize = 512 # samples\n",
    "overlap = 97 # %"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amplitude normalization \n",
    "\n",
    "Eventually, we also propose you different modes of data/spectrogram normalization.\n",
    "\n",
    "Normalization over raw data samples with the variable `data_normalization` (default value `''`, i.e. no normalization) :\n",
    "- instrument-based normalization with the three parameters `sensitivity_dB` (in dB, default value = 0), `gain` (in dB, default value = 0) and `peak_voltage` (in V, default value = 1). Using default values, no normalization will be performed ;\n",
    "\n",
    "- z-score normalization over a given time period through the variable `zscore_duration`, applied directly on your raw timeseries. The possible values are:\n",
    "    - `zscore_duration = 'original'` : the audio file duration will be used as time period ;\n",
    "    - `zscore_duration = '10H'` : any time period put as a string using classical [time alias](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#timeseries-offset-aliases). This period should be higher than your file duration. \n",
    "\n",
    "Normalization over spectra with the variable `spectro_normalization` (default value `'density'`, see OSmOSEanalytics/documentation/theory_spectrogram.pdf for details) :\n",
    "- density-based normalization by setting `spectro_normalization = 'density'`\n",
    "- spectrum-based normalization by setting `spectro_normalization = 'spectrum'` \n",
    "\n",
    "In the cell below, you can also have access to the amplitude dynamics in dB throuh the parameters `max_color_val` and `min_color_val`, the colormap `colmapspectros` to be used (see possible options in the [documentation](https://matplotlib.org/stable/tutorials/colors/colormaps.html)) and specify the frequency cut `fmin_HighPassFilter` of a high-pass filter if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_normalization = 'instrument' # 'instrument' OR 'zscore'\n",
    "\n",
    "zscore_duration = 'original' # parameter for 'zscore' mode, values = time alias OR 'original' \n",
    "sensitivity_dB = -164 # parameter for 'instrument' mode\n",
    "gain_dB = 14.7 # parameter for 'instrument' mode\n",
    "peak_voltage = 2.5 # parameter for 'instrument' mode\n",
    "\n",
    "spectro_normalization = 'density' # 'density' OR 'spectrum' \n",
    "\n",
    "max_color_val = 150\n",
    "min_color_val = 0\n",
    "colmapspectros = 'viridis'\n",
    "\n",
    "fmin_HighPassFilter = 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter adjustement \n",
    "\n",
    "\n",
    "In the cell below you can **check your spectrogram dimension w.r.t your screen resolution** (just run it). We calculate the number of time windows (or equivalently, the number of spectra) you have in your shortest spectrogram display window.\n",
    "\n",
    "Be aware that this number should be as close as your horizontal screen resolution (ie approximately 2000 pixels, as a classical screen resolution is 1920x1080 pixels (horizontal pixels) x (vertical pixels) ) to avoid numerical compression during image display on your screen, as well as useless over-resoluted spectrograms obtained at a high computational cost. We warn you if you are higher, but you can still compute higher-resolution spectrograms if you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.check_spectro_size()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`nberAdjustSpectros` is the number of spectrogram examples used to adjust your parameters. If you are really not sure about your parameters, it is better to start with a small number, because each time you will have to wait for the generation of all your `nberAdjustSpectros` (x the different zoom levels) spectrograms before being able to re-generate spectrograms with another set of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">*JUST RUN CELL*</span> Adjust spectrogram parameters\n",
    "\n",
    "### Compute `nberAdjustSpectros` spectrograms to adjust parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize `nberAdjustSpectros` spectrograms to adjust parameters. \n",
    "\n",
    "Re-run several times this cell to update the folder of images because they keep being generated while you visualize them. If this set of parameters does not suit you, change them and re-run new spectrograms with the previous cells, as many times as you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DONE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">*JUST RUN CELL*</span>  Prepare spectrogram generation\n",
    "\n",
    "Just one thing : if you create your spectrograms for an APLOSE campaign, set `write_datasets_csv_for_APLOSE=True` below !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_datasets_csv_for_APLOSE=False #TODO\n",
    "dataset.initialize()\n",
    "\n",
    "with open(f\"{dataset.Name}_wav_list.csv\", \"w\") as f:\n",
    "    path_to_list = os.path.realpath(f)\n",
    "    f.write(\"\\n\".join(dataset.list_wav_to_process))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">*JUST RUN CELL*</span> Launch spectrogram generation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might want to increase the dataset.Batch_number if the files needs to be split up in more than 10 groups, or decrease it if 10 groups are too much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.Batch_number = 10\n",
    "\n",
    "batch_size = len(dataset.list_wav_to_process) // dataset.Batch_number\n",
    "\n",
    "while dataset.Jb.Ongoing_jobs:\n",
    "    print(f\"\\rPlease wait for the following jobs to finish: {','.join(dataset.Jb.Ongoing_jobs)}\", end=\"\")\n",
    "\n",
    "print(\"\\rAll previous jobs are completed, ready to launch spectrograms\")\n",
    "\n",
    "jb = job_factory.Job_builder()\n",
    "for batch in range(dataset.Batch_number):\n",
    "    i_min = batch * batch_size\n",
    "    i_max = (i_min + batch_size if batch < dataset.Batch_number - 1 else len(dataset.list_wav_to_process)) # If it is the last batch, take all files\n",
    "\n",
    "    jobfile = jb.build_job_file(script_path=\"qsub_spectrogram_Generator.py\", \\\n",
    "                script_args=f\"--input-file-list {path_to_list} --dataset-path {dataset.Path} --analysis-fs {analysis_fs} \\\n",
    "                --ind-min {i_min} --ind-max {i_max}\", jobname=\"OSmOSE_SpectroGenerator\", preset=\"medium\")\n",
    "\n",
    "job_id_list = jb.submit_job() #submit all built job files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Track progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while jb.Ongoing_jobs:\n",
    "    for i in range(5):\n",
    "        print(f\"Ongoing jobs: {len(jb.Ongoing_jobs)}/{len(job_id_list)}; Finished jobs: {len(jb.Finished_jobs)}/{len(job_id_list)}{'.' * i}\")\n",
    "        sleep(1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bce92c0f8f81cdb158a63a7ee25a0fb0b2c55ab9a708ba2832e2eb9c8e94a3d1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

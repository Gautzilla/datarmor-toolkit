{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "from OSmOSE import Spectrogram, Job_builder, utils\n",
    "from time import sleep\n",
    "from IPython.display import Image\n",
    "\n",
    "path_osmose_dataset = \"/home/datawork-osmose/dataset/\"\n",
    "path_osmose_home = \"/home/datawork-osmose/\"\n",
    "os.chdir(Path(\"/home/datawork-osmose/osmose-datarmor/source\"))\n",
    "env_name = \"osmose\"\n",
    "\n",
    "jb = Job_builder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:blue\">*JUST RUN CELL*</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.display_folder_storage_infos(path_osmose_home)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">*FILL & RUN CELLS*</span> Dataset preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your dataset is part of a recording campaign, please provide its name with `campaign_name` ; in that case your dataset should be present in `home/datawork-osmose/dataset/{campaign_name}/{dataset_name}`. Otherwise let the default value `campaign_name = \"\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"boussole_MERMAID\"\n",
    "\n",
    "campaign_name = \"\"\n",
    "\n",
    "dataset = Spectrogram(\n",
    "    dataset_path=Path(path_osmose_dataset, campaign_name, dataset_name),\n",
    "    owner_group=\"gosmose\",\n",
    "    local=False,\n",
    ")\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">*FILL & RUN CELLS*</span> Configure spectrogram parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two following parameters `spectro_duration` (in s) and `dataset_sr` (in Hz) will allow you to process your data using different file durations (ie segmentation) and/or sampling rate (ie resampling) parameters. `spectro_duration` is the maximal duration of the spectrogram display window.\n",
    "\n",
    "To process audio files from your original folder (ie without any segmentation and/or resampling operations), use the original audio file duration and sample rate parameters estimated at your dataset uploading (they are printed in the previous cell). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.spectro_duration = 600  # seconds\n",
    "dataset.dataset_sr = 200  # Hz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, you can set the value of `zoom_levels`, which is the number of zoom levels you want (they are used in our web-based annotation tool APLOSE). With `zoom_levels = 0`, your shortest spectrogram display window has a duration of `spectro_duration` seconds (that is no zoom at all) ; with `zoom_levels = 1`, a duration of `spectro_duration`/2 seconds ; with `zoom_levels = 2`, a duration of `spectro_duration`/4 seconds ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.zoom_level = 2  # int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, you can set the following classical spectrogram parameters : `nfft` (in samples), `winsize` (in samples), `overlap` (in \\%). **Note that with those parameters you set the resolution of your spectrogram display window with the smallest duration, obtained with the highest zoom level.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.nfft = 1024  # samples\n",
    "dataset.window_size = 512  # samples\n",
    "dataset.overlap = 95  # %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case of audio segmentation, you can use the following variable `audio_file_overlap` (in seconds, default value = 0) to set an overlap in seconds between two consecutive segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.audio_file_overlap = 0  # seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amplitude normalization \n",
    "\n",
    "Eventually, we also propose you different modes of data/spectrogram normalization.\n",
    "\n",
    "Normalization over raw data samples with the variable `data_normalization` (default value `'none'`, i.e. no normalization) :\n",
    "- instrument-based normalization with the three parameters `sensitivity_dB` (in dB, default value = 0), `gain` (in dB, default value = 0) and `peak_voltage` (in V, default value = 1). Using default values, no normalization will be performed ;\n",
    "\n",
    "- z-score normalization over a given time period through the variable `zscore_duration`, applied directly on your raw timeseries. The possible values are:\n",
    "    - `zscore_duration = 'original'` : the audio file duration will be used as time period ;\n",
    "    - `zscore_duration = '10H'` : any time period put as a string using classical [time alias](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#timeseries-offset-aliases). This period should be higher than your file duration. \n",
    "\n",
    "Normalization over spectra with the variable `spectro_normalization` (default value `'density'`, see OSmOSEanalytics/documentation/theory_spectrogram.pdf for details) :\n",
    "- density-based normalization by setting `spectro_normalization = 'density'`\n",
    "- spectrum-based normalization by setting `spectro_normalization = 'spectrum'` \n",
    "\n",
    "In the cell below, you can also have access to the amplitude dynamics in dB throuh the parameters `dynamic_max` and `dynamic_min`, the colormap `spectro_colormap` to be used (see possible options in the [documentation](https://matplotlib.org/stable/tutorials/colors/colormaps.html)) and specify the frequency cut `HPfilter_freq_min` of a high-pass filter if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.data_normalization = \"instrument\"  # 'instrument' OR 'zscore' OR 'none'\n",
    "\n",
    "dataset.zscore_duration = (\n",
    "    \"original\"  # parameter for 'zscore' mode, values = time alias OR 'original'\n",
    ")\n",
    "dataset.sensitivity = -170  # parameter for 'instrument' mode\n",
    "dataset.gain_dB = 10  # parameter for 'instrument' mode\n",
    "dataset.peak_voltage = 1.5  # parameter for 'instrument' mode\n",
    "\n",
    "dataset.spectro_normalization = \"spectrum\"  # 'density' OR 'spectrum'\n",
    "\n",
    "dataset.dynamic_max = 40  # dB\n",
    "dataset.dynamic_min = -40  # dB\n",
    "dataset.colormap = \"viridis\"\n",
    "\n",
    "dataset.hp_filter_min_freq = 1  # Hz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter adjustement \n",
    "\n",
    "\n",
    "In the cell below you can **check your spectrogram dimension w.r.t your screen resolution** (just run it). We calculate the number of time windows (or equivalently, the number of spectra) you have in your shortest spectrogram display window.\n",
    "\n",
    "Be aware that this number should be as close as your horizontal screen resolution (ie approximately 2000 pixels, as a classical screen resolution is 1920x1080 pixels (horizontal pixels) x (vertical pixels) ) to avoid numerical compression during image display on your screen, as well as useless over-resoluted spectrograms obtained at a high computational cost. We warn you if you are higher, but you can still compute higher-resolution spectrograms if you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.check_spectro_size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">*FILL & RUN CELL*</span> Adjust spectrogram parameters and initialize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`dataset.number_adjustment_spectrograms` is the number of spectrogram examples used to adjust your parameters. If you are really not sure about your parameters, it is better to start with a small number, because each time you will have to wait for the generation of all your `dataset.number_adjustment_spectrograms` (x the different zoom levels) spectrograms before being able to re-generate spectrograms with another set of parameters.\n",
    "\n",
    "`dataset.batch_number` indicates the number of concurrent jobs. A higher number can speed things up until a certain point. It still does not work very well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.number_adjustment_spectrogram = 3\n",
    "dataset.batch_number = 4\n",
    "\n",
    "reshape_method = \"classic\"  # Automatically reshape the audio files to fit the spectro_duration value. Available methods : \"classic\" or \"legacy\"\n",
    "merge_on_reshape = False  # Set to False if fyou don't want to merge audio files while reshaping them (if they do not follow each other chronologically for example)\n",
    "force_init = False  # Force every initialization parameter, including force_reshape and other computing jobs. It is best to avoid using it.\n",
    "dataset.initialize(\n",
    "    reshape_method=reshape_method,\n",
    "    force_init=force_init,\n",
    "    merge_on_reshape=merge_on_reshape,\n",
    ")\n",
    "dataset.update_parameters(\n",
    "    dataset.path.joinpath(\"processed\", \"spectrogram\", \"adjust_metadata.csv\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">*JUST RUN CELLS*</span> Adjust spectrogram parameters\n",
    "\n",
    "### Compute `dataset.number_adjustment_spectrograms` spectrograms to adjust parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the variable `file_list` in the cell below to adjust your spectrogram parameters on specific files; put their names in this list as follows, eg `file_list = ['2020_06_05T15_10_00.wav','2020_06_07T15_41_40.wav','2020_06_09T16_13_20.wav','2020_06_05T15_41_40.wav']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_list = [\n",
    "    \"\"\n",
    "]  # Fill audio file names when you want to generate specific adjustment spectrograms\n",
    "dataset.save_spectro_metadata(True)\n",
    "jobfile = jb.build_job_file(\n",
    "    script_path=Path(os.getcwd(), \"qsub_spectrogram_generator_pkg.py\"),\n",
    "    script_args=f\"\"\"--nb-adjust-files {dataset.number_adjustment_spectrogram} \\\n",
    "            --dataset-path {dataset.path} \\\n",
    "            --dataset-sr {dataset.dataset_sr} \\\n",
    "            --files \"{\" \".join(file_list)}\" \"\"\",\n",
    "    jobname=\"OSmOSE_AdjustSpectro\",\n",
    "    preset=\"low\",\n",
    "    env_name=env_name,\n",
    "    mem=\"20G\",\n",
    "    walltime=\"01:00:00\",\n",
    "    logdir=dataset.path.joinpath(\"log\"),\n",
    ")\n",
    "\n",
    "pending_jobs = [\n",
    "    jobid\n",
    "    for jobid in dataset.pending_jobs\n",
    "    if b\"finished\" not in subprocess.run([\"qstat\", jobid], capture_output=True).stderr\n",
    "]\n",
    "job_id = jb.submit_job(dependency=pending_jobs)  # submit all built job files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize `nberAdjustSpectros` spectrograms to adjust parameters. \n",
    "\n",
    "Re-run several times this cell to update the folder of images because they keep being generated while you visualize them. If this set of parameters does not suit you, change them and re-run new spectrograms with the previous cells, as many times as you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if jb.ongoing_jobs:\n",
    "    print(f\"\\rParameter adjustment is still running, come back later!\")\n",
    "else:\n",
    "    print(\"\\rParameter adjustment finished!                       \\n    \")\n",
    "\n",
    "    path_output_spectro = dataset.path_output_spectrogram.parent.parent.joinpath(\n",
    "        \"adjustment_spectros\", \"image\"\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        \"Please find below your spectrograms, and below them some details on their data\\n\"\n",
    "    )\n",
    "\n",
    "    spectro_list = os.listdir(path_output_spectro)\n",
    "    for spectro in spectro_list:\n",
    "        display(Image(path_output_spectro.joinpath(spectro)))\n",
    "\n",
    "    jb.read_output_file(outtype=\"out\", job_file_name=jb.finished_jobs[-1][\"outfile\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">*JUST RUN CELL*</span>  Prepare spectrogram generation\n",
    "\n",
    "Just one thing : if you create your spectrograms for an APLOSE campaign, set `write_datasets_csv_for_APLOSE=True` below !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_datasets_csv_for_APLOSE = False\n",
    "\n",
    "if write_datasets_csv_for_APLOSE:\n",
    "\n",
    "    dataset_csv = Path(path_osmose_dataset, \"datasets.csv\")\n",
    "\n",
    "    dataset_name = f\"{dataset.name} ({dataset.spectro_duration}_{dataset.dataset_sr})\"\n",
    "    dataset_info = {\n",
    "        \"name\": dataset_name,\n",
    "        \"folder_name\": dataset.name,\n",
    "        \"conf_folder\": f\"{dataset.spectro_duration}_{dataset.dataset_sr}\",\n",
    "        \"dataset_type_name\": \"\",\n",
    "        \"dataset_type_desc\": \"\",\n",
    "        \"files_type\": \".wav\",\n",
    "        \"location_name\": \"\",\n",
    "        \"location_desc\": \"\",\n",
    "        \"location_lat\": \"\",\n",
    "        \"location_lon\": \"\",\n",
    "    }\n",
    "\n",
    "    if dataset_csv.exists():\n",
    "        meta = pd.read_csv(dataset_csv)\n",
    "        if dataset_name not in meta[\"name\"].values:\n",
    "            meta = meta.append(dataset_info, ignore_index=True)\n",
    "            meta.sort_values(by=[\"folder_name\"], ascending=False)\n",
    "            meta.to_csv(dataset_csv, index=False)\n",
    "\n",
    "    else:\n",
    "        met = pd.DataFrame.from_records([df2])\n",
    "        met.to_csv(dataset_csv, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">*JUST RUN CELL*</span> Launch spectrogram generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For debug: if this cell fails, run it again please, can faile twice in a row**\n",
    "\n",
    "The variable below `save_matrix` should be set to True if you want to generate the numpy matrices along your png spectrograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_matrix = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.batch_number = 8\n",
    "all_files = list(dataset.audio_path.glob(\"*.wav\"))\n",
    "batch_size = len(all_files) // dataset.batch_number\n",
    "\n",
    "dataset.save_spectro_metadata(False)\n",
    "\n",
    "for batch in range(dataset.batch_number):\n",
    "    i_min = batch * batch_size\n",
    "    i_max = (\n",
    "        i_min + batch_size if batch < dataset.batch_number - 1 else len(all_files)\n",
    "    )  # If it is the last batch, take all files\n",
    "\n",
    "    jobfile = jb.build_job_file(\n",
    "        script_path=Path(os.getcwd(), \"qsub_spectrogram_generator_pkg.py\"),\n",
    "        script_args=f\"--dataset-path {dataset.path}\\\n",
    "                --dataset-sr {dataset.dataset_sr} \\\n",
    "                --batch-ind-min {i_min}\\\n",
    "                --batch-ind-max {i_max}\\\n",
    "                {'--save-matrix' if save_matrix else ''}\",\n",
    "        jobname=\"OSmOSE_SpectroGenerator\",\n",
    "        preset=\"low\",\n",
    "        env_name=env_name,\n",
    "        mem=\"70G\",\n",
    "        walltime=\"10:00:00\",\n",
    "        logdir=dataset.path.joinpath(\"log\"),\n",
    "    )\n",
    "\n",
    "\n",
    "job_id_list = jb.submit_job()  # submit all built job files\n",
    "nb_jobs = len(jb.finished_jobs) + len(job_id_list)\n",
    "\n",
    "print(f\"The job ids are {job_id_list}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Track progress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check job status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if jb.ongoing_jobs:\n",
    "    spectros = len(os.listdir(dataset.path_output_spectrogram))\n",
    "    audio = len(os.listdir(dataset.audio_path)) - 2\n",
    "    total = audio * (2**dataset.zoom_level) - 1\n",
    "\n",
    "    print(\n",
    "        f\"Ongoing jobs: {len(jb.ongoing_jobs)}/{nb_jobs}; Finished jobs: {len(jb.finished_jobs)}/{nb_jobs}...\"\n",
    "    )\n",
    "    print(f\"Spectrograms: {spectros}/{total} ({spectros*100//total}%).\")\n",
    "\n",
    "else:\n",
    "    print(\"All jobs are finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read output files\n",
    "\n",
    "Use the cell below to read the output files of your job. You have two available job builders to chose from :\n",
    " \n",
    " - dataset.jb to read the output of dataset initialization jobs.\n",
    " - jb to read the output of spectrogram generation jobs.\n",
    " \n",
    "Once you've chosen the job_builder, select an output file name to read. You can set the read mode to err if you wish to read the error output file (usually empty)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_builder = jb  # jb or dataset.jb\n",
    "\n",
    "job_builder.list_jobs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "job_to_read = \"OSmOSE_SpectroGenerator2\"\n",
    "read_mode = \"out\"  # set to \"err\" to read the error output file\n",
    "\n",
    "job_builder.read_output_file(outtype=read_mode, job_name=job_to_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.jb.update_job_access()\n",
    "jb.update_job_access()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_id = \"\"  # Get the job id from the list above\n",
    "\n",
    "!qstat -fx {job_id}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for jobinfo in job_builder.ongoing_jobs:\n",
    "    jobinfo[\"path\"].unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_builder.finished_jobs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:osmose]",
   "language": "python",
   "name": "conda-env-osmose-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "038fb172a99c9b7ee7474e984b9ff4962ea47b0ef555bcc216ed798a8387f59b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
